# GAN-lab

## 專案介紹
本專案以 **CelebA Faces dataset** 為基礎，實作並比較多種生成對抗網路 (GAN) 架構，探討其在 **訓練穩定性** 與 **生成影像品質** 上的差異。  

比較模型包含：
- **DCGAN**
- **WGAN-GP**
- **LSGAN**
- **InfoGAN**

---

## 背景與動機
生成對抗網路 (GAN) 是深度學習領域中重要的生成模型，但在實作過程中常遇到模式崩潰 (mode collapse)、梯度消失或爆炸、訓練失衡等問題。本專案希望透過不同變體的比較，理解各方法在收斂速度、穩定性及影像品質上的差異。

---

## 實作模型與架構

### DCGAN
- **優點**：透過卷積與轉置卷積擷取特徵，能生成更具結構的圖片  
- **訓練參數**：Adam, BCE Loss, lr=0.0002, β=0.999, batch=128, epoch=20  
- **觀察**：
  - 初版訓練曲線震盪劇烈，顯示判別器過強與模式崩潰。
  - 改善版將激活函數改為 LeakyReLU、調整學習率並對輸入加噪聲後，震盪幅度減小、穩定性提升。

---

### WGAN-GP
- **特色**：以 gradient penalty 取代 weight clipping，改善梯度裁剪限制。  
- **訓練參數**：Adam, Wasserstein Loss + Gradient Penalty, lr=0.0001, batch=128, epoch=50, λ=10  
- **觀察**：
  - Critic Loss 初期極端負值，但逐漸收斂至 0 附近並趨於穩定。  
  - Generator Loss 下降後穩定維持在合理區間，未出現模式崩潰。  
  - **生成結果較 DCGAN 更真實、平滑**。

---

### LSGAN
- **特色**：使用 least squares loss 改善梯度傳遞。  
- **訓練參數**：Adam, L2 Loss, lr=0.0002/0.00005, batch=128, epoch=50  
- **觀察**：
  - 初期 loss 高且震盪，但中段迅速收斂至低值。  
  - 後期出現震盪與部分模式崩潰。  
  - 生成圖像已具備人臉主要特徵，但細節不足，仍有模糊情況。

---

### InfoGAN
- **特色**：引入 latent code 並最大化互資訊 (mutual information)，嘗試提升可解釋性。  
- **訓練參數**：Adam (β₁=0.5, β₂=0.999), BCE + MSE + CrossEntropy, latent=62, category=10, code=2, epoch=200  
- **觀察**：
  - Loss 曲線穩定，生成器與判別器保持平衡。  
  - 生成圖像品質不佳，未優於 DCGAN/WGAN-GP/LSGAN，顯示模型容量與資料集複雜度對效果影響大。

---

## 實驗結果比較

| 模型      | 訓練穩定性 | 收斂速度 | 影像品質 | 備註 |
|-----------|------------|----------|----------|------|
| **DCGAN**   | 不穩定，震盪劇烈 | 中等 | 普通 | 改進後穩定性稍提升 |
| **WGAN-GP** | 最穩定 | 較慢 | 最佳 | Loss 平滑，無模式崩潰 |
| **LSGAN**   | 中等，有震盪 | 初期快 | 中等 | 後期品質仍不足 |
| **InfoGAN** | 穩定 | 較慢 | 普通 | 可解釋性強，但生成品質不佳 |

---

## 總結
- **WGAN-GP**：雖訓練時間較久，但收斂穩定且生成影像最佳。  
- **LSGAN**：初期收斂快，但後期品質不如 WGAN-GP。  
- **InfoGAN**：提供可解釋性，但影像品質不佳。  
- **DCGAN**：作為基準模型，生成結果一般，需調整超參數改善穩定性。  

👉 本實驗顯示，**WGAN-GP** 在穩定性與生成效果上最優；**LSGAN** 則適合快速實驗；**InfoGAN** 的潛在可解釋性值得進一步研究。

---

## 未來方向
- 加入 **StyleGAN/StyleGAN2** 進行更高解析度影像生成。  
- 嘗試 **Diffusion Models** 作為比較基準。  
- 探討更多正則化方法以提升 InfoGAN 的生成品質。  

---
